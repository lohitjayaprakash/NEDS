# NEDS: Neural Encoding and Decoding at Scale - Architecture Documentation

## Overview

NEDS is a revolutionary multimodal transformer-based model that simultaneously handles neural signals (spike data + LFP) and behavioral data for both encoding and decoding tasks using a novel multi-task masking strategy.

## Table of Contents
- [Model Architecture](#model-architecture)
- [Data Flow Pipeline](#data-flow-pipeline)
- [Multi-Task Masking Strategy](#multi-task-masking-strategy)
- [Session Stitching](#session-stitching)
- [Training Modes](#training-modes)
- [Data Specifications](#data-specifications)
- [Key Innovations](#key-innovations)

---

## Model Architecture

### Core Components Overview

```mermaid
graph TB
    subgraph "Input Data"
        A1[Neural Data<br/>Spike Trains]
        A2[LFP Data<br/>Optional]
        A3[Static Behavior<br/>choice, block]
        A4[Dynamic Behavior<br/>wheel, whisker]
    end
    
    subgraph "Encoder Embeddings"
        B1[Session Embeddings<br/>Handle variable neurons]
        B2[Modality Embeddings<br/>5 modality types]
        B3[Positional Embeddings<br/>Temporal positions]
        B4[Stitching Layer<br/>Variable dimensions]
    end
    
    subgraph "Multi-Task Masker"
        C1[Encoding Mask<br/>Neural â†’ Behavior]
        C2[Decoding Mask<br/>Behavior â†’ Neural]
        C3[Self-Modality Mask<br/>Within modality]
        C4[Cross-Modality Mask<br/>Between modalities]
        C5[Random Token Mask<br/>Temporal masking]
    end
    
    subgraph "Transformer Backbone"
        D1[Multi-Head Attention<br/>with RoPE]
        D2[Layer Normalization]
        D3[MLP Layers]
        D4[5 Transformer Layers]
    end
    
    subgraph "Output Decoders"
        E1[Spike Decoder<br/>Poisson NLL Loss]
        E2[Dynamic Decoder<br/>MSE Loss]
        E3[Static Decoder<br/>CrossEntropy Loss]
        E4[Session Stitching<br/>Variable outputs]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B2
    A4 --> B2
    
    B1 --> B4
    B2 --> B3
    B3 --> C1
    B4 --> C2
    
    C1 --> D1
    C2 --> D1
    C3 --> D2
    C4 --> D3
    C5 --> D4
    
    D1 --> E1
    D2 --> E2
    D3 --> E3
    D4 --> E4
```

### Detailed Architecture Diagram

```
ğŸ§  NEURAL DATA                    ğŸ“Š SESSION EMBEDDINGS              ğŸ­ MIXED MASKING                   ğŸ” MULTI-HEAD ATTENTION            âš¡ SPIKE PREDICTION
â€¢ Spike trains (20ms bins)    â†’   â€¢ Handle 100-800 neurons       â†’   â€¢ Random scheme selection      â†’   â€¢ 8 attention heads            â†’   â€¢ Poisson distribution
â€¢ LFP features (optional)         â€¢ Session-specific parameters      â€¢ Batch-wise variation             â€¢ Flash attention optimized        â€¢ Count data modeling
â€¢ Variable neurons per session                                                                                                               
                                       â†“                                     â†“                                     â†“                              â†“
ğŸ­ BEHAVIORAL DATA                ğŸ”„ MODALITY EMBEDDINGS              â†’ ENCODING: Mask behavior          ğŸ“ LAYER NORMALIZATION             ğŸ¯ BEHAVIOR PREDICTION
â€¢ Static: choice, block       â†’   â€¢ 5 modality types             â†’   â† DECODING: Mask neural       â†’   â€¢ ScaleNorm option             â†’   â€¢ MSE for continuous
â€¢ Dynamic: wheel, whisker         â€¢ Cross-modal attention            â†» SELF: Within modality           â€¢ Gradient stabilization           â€¢ CrossEntropy for discrete
â€¢ Continuous signals                                                 â†” CROSS: Between modality                                             
                                       â†“                                     â†“                                     â†“                              â†“
                                  ğŸ“ POSITION EMBEDDINGS              TEMPORAL MASKING                   ï¿½ MLP LAYERS                       ğŸ§© SESSION STITCHING
                                  â€¢ Temporal sequences                â€¢ Consecutive time bins            â€¢ GELU activation                   â€¢ Variable output dimensions
                                  â€¢ RoPE encoding                     â€¢ 30% masking ratio               â€¢ 512 intermediate dim              â€¢ Session-specific decoders
                                                                                                              â†“
                                                                                                         ğŸ“š 5-LAYER STACK
                                                                                                         â€¢ Residual connections
                                                                                                         â€¢ 256 hidden dimensions
```

**Notion-Compatible Flow Chart:**

```
INPUT LAYER:
â”œâ”€â”€ ğŸ§  Neural Data (Spikes + LFP)
â””â”€â”€ ğŸ­ Behavioral Data (Static + Dynamic)
    â†“
EMBEDDING LAYER:
â”œâ”€â”€ ğŸ“Š Session Embeddings (Handle variable neurons)
â”œâ”€â”€ ğŸ”„ Modality Embeddings (5 types)
â””â”€â”€ ğŸ“ Position Embeddings (RoPE)
    â†“
MASKING STRATEGY:
â”œâ”€â”€ ğŸ­ Mixed Masking (Random selection)
â”œâ”€â”€ â†’ Encoding (Mask behavior)
â”œâ”€â”€ â† Decoding (Mask neural)
â”œâ”€â”€ â†» Self-Modality (Within modality)
â””â”€â”€ â†” Cross-Modality (Between modalities)
    â†“
TRANSFORMER CORE:
â”œâ”€â”€ ğŸ” Multi-Head Attention (8 heads, Flash optimized)
â”œâ”€â”€ ğŸ“ Layer Normalization (ScaleNorm option)
â”œâ”€â”€ ğŸ”¢ MLP Layers (GELU, 512 dim)
â””â”€â”€ ğŸ“š 5-Layer Stack (Residual, 256 hidden)
    â†“
OUTPUT LAYER:
â”œâ”€â”€ âš¡ Spike Prediction (Poisson NLL)
â”œâ”€â”€ ğŸ¯ Behavior Prediction (MSE/CrossEntropy)
â””â”€â”€ ğŸ§© Session Stitching (Variable dimensions)
```

---

## Data Flow Pipeline

### Complete Data Processing Pipeline

```mermaid
flowchart TD
    subgraph "Raw Data Sources"
        IBL["ğŸ—„ï¸ IBL Database<br/>â€¢ 84 experimental sessions<br/>â€¢ Standardized mouse behavior<br/>â€¢ Multi-region recordings"]
        ONE["ğŸ”Œ ONE API<br/>â€¢ Data access interface<br/>â€¢ Automatic caching<br/>â€¢ Session metadata"]
    end
    
    subgraph "Data Preprocessing"
        PrepData["ğŸ“‹ prepare_data.py<br/>â€¢ Download neural & behavioral data<br/>â€¢ Spike binning (20ms)<br/>â€¢ Behavioral alignment<br/>â€¢ Quality filtering"]
        
        SpikeProc["âš¡ Spike Processing<br/>â€¢ Bin to 20ms windows<br/>â€¢ Filter responsive neurons<br/>â€¢ Sparse matrix storage"]
        
        BehProc["ğŸ¯ Behavior Processing<br/>â€¢ Wheel speed extraction<br/>â€¢ Whisker motion energy<br/>â€¢ Choice/block categorization"]
        
        LFPProc["ğŸŒŠ LFP Processing (Optional)<br/>â€¢ Signal filtering & referencing<br/>â€¢ Power spectral density<br/>â€¢ Frequency band features"]
    end
    
    subgraph "Dataset Creation"
        CreateDS["ğŸ“¦ create_dataset.py<br/>â€¢ Convert to HuggingFace format<br/>â€¢ Train/val/test splits (70/10/20)<br/>â€¢ Memory-efficient storage"]
        
        DataSplit["ğŸ“Š Data Partitioning<br/>â€¢ Session-wise splits<br/>â€¢ Trial-wise splits<br/>â€¢ Cross-session validation"]
        
        NPYSave["ğŸ’¾ NumPy Storage<br/>â€¢ Efficient .npy format<br/>â€¢ Batch-friendly structure<br/>â€¢ Fast loading during training"]
    end
    
    subgraph "Training Pipeline"
        DataLoader["ğŸ“¥ Data Loading<br/>â€¢ Length-grouped batching<br/>â€¢ Session-aware sampling<br/>â€¢ Multimodal alignment"]
        
        ModelTrain["ğŸ“ Model Training<br/>â€¢ Mixed masking strategy<br/>â€¢ Multimodal fusion<br/>â€¢ Cross-session generalization"]
        
        Eval["ğŸ“ˆ Evaluation<br/>â€¢ Encoding performance<br/>â€¢ Decoding accuracy<br/>â€¢ Cross-modal prediction"]
    end
    
    IBL --> ONE
    ONE --> PrepData
    PrepData --> SpikeProc
    PrepData --> BehProc
    PrepData --> LFPProc
    
    SpikeProc --> CreateDS
    BehProc --> CreateDS
    LFPProc --> CreateDS
    
    CreateDS --> DataSplit
    DataSplit --> NPYSave
    
    NPYSave --> DataLoader
    DataLoader --> ModelTrain
    ModelTrain --> Eval
    
    style IBL fill:#e1f5fe
    style PrepData fill:#f3e5f5
    style CreateDS fill:#e8f5e8
    style ModelTrain fill:#fff3e0
```

### Data Transformation Flow

```mermaid
graph LR
    subgraph "Raw Neural Data"
        A1["ğŸ”¬ Raw Spikes<br/>â€¢ Continuous timestamps<br/>â€¢ Variable trial lengths<br/>â€¢ Multiple brain regions"]
        A2["ğŸ“¡ Raw LFP<br/>â€¢ 2500 Hz sampling<br/>â€¢ Multi-channel recordings<br/>â€¢ Continuous voltage"]
    end
    
    subgraph "Binned Neural Data"
        B1["ğŸ“Š Binned Spikes<br/>â€¢ 20ms time bins<br/>â€¢ Poisson count data<br/>â€¢ (trials Ã— time Ã— neurons)"]
        B2["ğŸŒŠ LFP Features<br/>â€¢ Power spectral density<br/>â€¢ 5 frequency bands<br/>â€¢ (trials Ã— time Ã— features)"]
    end
    
    subgraph "Behavioral Data"
        C1["ğŸ¯ Trial Events<br/>â€¢ Stimulus onset<br/>â€¢ Choice decisions<br/>â€¢ Reward delivery"]
        C2["ğŸ“ Continuous Signals<br/>â€¢ Wheel position<br/>â€¢ Whisker motion<br/>â€¢ Eye movements"]
    end
    
    subgraph "Aligned Multimodal Data"
        D1["ğŸ”„ Temporal Alignment<br/>â€¢ Common time base<br/>â€¢ Stimulus-locked<br/>â€¢ 100 time bins per trial"]
        D2["ğŸ“‹ Trial Structure<br/>â€¢ -500ms to +1500ms<br/>â€¢ Around stimulus onset<br/>â€¢ Standardized format"]
    end
    
    subgraph "Model-Ready Data"
        E1["ğŸ­ Masked Inputs<br/>â€¢ Dynamic masking<br/>â€¢ Task-specific patterns<br/>â€¢ Training objectives"]
        E2["ğŸ¯ Prediction Targets<br/>â€¢ Modality-specific<br/>â€¢ Loss-function ready<br/>â€¢ Cross-modal tasks"]
    end
    
    A1 --> B1
    A2 --> B2
    C1 --> D1
    C2 --> D2
    
    B1 --> D1
    B2 --> D1
    D1 --> E1
    D2 --> E2
    
    style A1 fill:#ffebee
    style B1 fill:#e8f5e8
    style D1 fill:#e3f2fd
    style E1 fill:#fff8e1
```

---

## Multi-Task Masking Strategy

### Masking Scheme Overview

```mermaid
graph TD
    subgraph "Mixed Masking Strategy"
        A["ğŸ² Random Scheme Selection<br/>Per batch, randomly choose masking strategy"]
        
        B1["ğŸ§ â†’ğŸ¯ Encoding<br/>Mask: Behavioral data<br/>Predict: From neural signals<br/>Task: Neural â†’ Behavior"]
        
        B2["ğŸ¯â†’ğŸ§  Decoding<br/>Mask: Neural data<br/>Predict: From behavioral signals<br/>Task: Behavior â†’ Neural"]
        
        B3["ğŸ”„ Self-Modality<br/>Mask: Within same modality<br/>Predict: Missing parts<br/>Task: Intra-modal completion"]
        
        B4["â†”ï¸ Cross-Modality<br/>Mask: Across modalities<br/>Predict: From other modalities<br/>Task: Inter-modal translation"]
        
        B5["ğŸ­ Random Token<br/>Mask: Random temporal positions<br/>Predict: Masked time bins<br/>Task: Temporal prediction"]
    end
    
    subgraph "Masking Implementation"
        C1["âš™ï¸ Temporal Masking<br/>â€¢ Consecutive time bins<br/>â€¢ Expandable windows<br/>â€¢ 30% masking ratio"]
        
        C2["ğŸ§© Modality-Specific<br/>â€¢ Neural vs Behavioral<br/>â€¢ Static vs Dynamic<br/>â€¢ Session-aware"]
        
        C3["ğŸ¯ Target Generation<br/>â€¢ Ground truth alignment<br/>â€¢ Loss computation<br/>â€¢ Performance metrics"]
    end
    
    A --> B1
    A --> B2
    A --> B3
    A --> B4
    A --> B5
    
    B1 --> C1
    B2 --> C1
    B3 --> C2
    B4 --> C2
    B5 --> C3
    
    style A fill:#e1f5fe
    style B1 fill:#e8f5e8
    style B2 fill:#fff3e0
    style B3 fill:#f3e5f5
    style B4 fill:#fce4ec
    style B5 fill:#e0f2f1
```

### Task-Specific Masking Patterns

```mermaid
graph LR
    subgraph "Input Data Timeline"
        T1["T1"] --> T2["T2"] --> T3["T3"] --> T4["T4"] --> T5["T5"]
    end
    
    subgraph "Encoding Task"
        E1["ğŸ§  Neural"] --> E2["ğŸ§  Neural"] --> E3["âŒ Masked"] --> E4["âŒ Masked"] --> E5["ğŸ§  Neural"]
        E11["âŒ Masked"] --> E12["âŒ Masked"] --> E13["ğŸ¯ Behavior"] --> E14["ğŸ¯ Behavior"] --> E15["âŒ Masked"]
    end
    
    subgraph "Decoding Task"
        D1["âŒ Masked"] --> D2["âŒ Masked"] --> D3["ğŸ§  Neural"] --> D4["ğŸ§  Neural"] --> D5["âŒ Masked"]
        D11["ğŸ¯ Behavior"] --> D12["ğŸ¯ Behavior"] --> D13["âŒ Masked"] --> D14["âŒ Masked"] --> D15["ğŸ¯ Behavior"]
    end
    
    subgraph "Self-Modality Task"
        S1["ğŸ§  Neural"] --> S2["âŒ Masked"] --> S3["âŒ Masked"] --> S4["ğŸ§  Neural"] --> S5["ğŸ§  Neural"]
        S11["ğŸ¯ Behavior"] --> S12["ğŸ¯ Behavior"] --> S13["âŒ Masked"] --> S14["âŒ Masked"] --> S15["ğŸ¯ Behavior"]
    end
    
    T1 -.-> E1
    T2 -.-> E2
    T3 -.-> E3
    T4 -.-> E4
    T5 -.-> E5
    
    style E3 fill:#ffcdd2
    style E4 fill:#ffcdd2
    style E11 fill:#ffcdd2
    style E12 fill:#ffcdd2
    style E15 fill:#ffcdd2
```

---

## Session Stitching

### Variable Neuron Count Handling

```mermaid
graph TB
    subgraph "Problem: Variable Neuron Counts"
        A1["Session A<br/>150 neurons"]
        A2["Session B<br/>300 neurons"] 
        A3["Session C<br/>500 neurons"]
        A4["Session D<br/>120 neurons"]
    end
    
    subgraph "Solution: Stitching Architecture"
        B1["ğŸ§© Stitch Encoder<br/>â€¢ Session-specific input layers<br/>â€¢ Normalize to hidden dim<br/>â€¢ Learnable transformations"]
        
        B2["ğŸ”„ Shared Transformer<br/>â€¢ Fixed hidden dimension<br/>â€¢ Cross-session learning<br/>â€¢ Common representations"]
        
        B3["ğŸ¯ Stitch Decoder<br/>â€¢ Session-specific output layers<br/>â€¢ Variable output dimensions<br/>â€¢ Flexible predictions"]
    end
    
    subgraph "Implementation Details"
        C1["ğŸ“Š Session Mapping<br/>â€¢ EID â†’ neuron count<br/>â€¢ Dynamic layer creation<br/>â€¢ Parameter dictionaries"]
        
        C2["âš™ï¸ Forward Pass<br/>â€¢ Batch session grouping<br/>â€¢ Parallel processing<br/>â€¢ Efficient computation"]
        
        C3["ğŸ“ Training Strategy<br/>â€¢ Session-aware batching<br/>â€¢ Gradient accumulation<br/>â€¢ Cross-session generalization"]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    A4 --> B1
    
    B1 --> B2
    B2 --> B3
    
    B1 --> C1
    B2 --> C2
    B3 --> C3
    
    style B1 fill:#e3f2fd
    style B2 fill:#e8f5e8
    style B3 fill:#fff3e0
```

### Stitching Implementation Flow

```mermaid
sequenceDiagram
    participant Input as Input Data
    participant Encoder as Stitch Encoder
    participant Transformer as Shared Transformer
    participant Decoder as Stitch Decoder
    participant Output as Variable Outputs
    
    Note over Input: Sessions with different<br/>neuron counts (100-800)
    
    Input->>Encoder: Batch with session IDs
    Note over Encoder: Session-specific<br/>linear layers
    
    Encoder->>Encoder: Group by session EID
    Encoder->>Encoder: Apply session-specific<br/>transformation
    Encoder->>Transformer: Fixed 256-dim vectors
    
    Note over Transformer: Shared parameters<br/>across all sessions
    
    Transformer->>Transformer: Multi-head attention
    Transformer->>Transformer: Layer normalization
    Transformer->>Transformer: MLP processing
    Transformer->>Decoder: Contextualized features
    
    Decoder->>Decoder: Group by session EID
    Decoder->>Decoder: Apply session-specific<br/>output layers
    Decoder->>Output: Variable-sized predictions
    
    Note over Output: Session-appropriate<br/>output dimensions
```

---

## Training Modes

### Three Primary Training Configurations

```mermaid
graph TD
    subgraph "Training Mode Selection"
        A["ğŸ›ï¸ Model Mode Selection"]
        
        A --> B1["ğŸ”„ Multimodal (mm)<br/>â€¢ All modalities active<br/>â€¢ Mixed masking strategy<br/>â€¢ Joint encoding/decoding"]
        
        A --> B2["ğŸ§ â†’ğŸ¯ Encoding Only<br/>â€¢ Neural â†’ Behavioral<br/>â€¢ Behavioral data targets<br/>â€¢ Decoding neural activity"]
        
        A --> B3["ğŸ¯â†’ğŸ§  Decoding Only<br/>â€¢ Behavioral â†’ Neural<br/>â€¢ Neural data targets<br/>â€¢ Encoding behavior to spikes"]
    end
    
    subgraph "Session Scaling"
        C1["ğŸ‘¤ Single Session<br/>â€¢ One experimental session<br/>â€¢ Session-specific learning<br/>â€¢ Fine-grained analysis"]
        
        C2["ğŸ‘¥ Multi-Session<br/>â€¢ 10-70 sessions<br/>â€¢ Cross-session learning<br/>â€¢ Generalization focus"]
        
        C3["ğŸŒ Large Scale<br/>â€¢ 70+ sessions<br/>â€¢ Population-level patterns<br/>â€¢ Maximum generalization"]
    end
    
    subgraph "Training Infrastructure"
        D1["ğŸ–¥ï¸ Single GPU<br/>â€¢ Development/debugging<br/>â€¢ Small-scale experiments<br/>â€¢ Local training"]
        
        D2["ğŸ–¥ï¸ğŸ–¥ï¸ Multi-GPU<br/>â€¢ Distributed training<br/>â€¢ Large batch sizes<br/>â€¢ Faster convergence"]
        
        D3["ğŸ” Hyperparameter Search<br/>â€¢ Ray Tune integration<br/>â€¢ Automated optimization<br/>â€¢ Performance maximization"]
    end
    
    B1 --> C1
    B1 --> C2
    B1 --> C3
    
    C1 --> D1
    C2 --> D2
    C3 --> D3
    
    style B1 fill:#e3f2fd
    style B2 fill:#e8f5e8
    style B3 fill:#fff3e0
```

### Evaluation Framework

```mermaid
graph LR
    subgraph "Model Evaluation"
        A1["ğŸ“Š Cross-Session Testing<br/>â€¢ Train on 74 sessions<br/>â€¢ Test on 10 held-out<br/>â€¢ Generalization assessment"]
        
        A2["ğŸ”„ Cross-Modal Tasks<br/>â€¢ Neuralâ†’Behavioral accuracy<br/>â€¢ Behavioralâ†’Neural fidelity<br/>â€¢ Multimodal coherence"]
        
        A3["â±ï¸ Temporal Prediction<br/>â€¢ Future state prediction<br/>â€¢ Sequence modeling<br/>â€¢ Temporal dynamics"]
    end
    
    subgraph "Performance Metrics"
        B1["ğŸ“ˆ Encoding Metrics<br/>â€¢ RÂ² correlation<br/>â€¢ Prediction accuracy<br/>â€¢ Behavioral decoding"]
        
        B2["ğŸ¯ Decoding Metrics<br/>â€¢ Spike prediction error<br/>â€¢ Poisson likelihood<br/>â€¢ Neural fidelity"]
        
        B3["ğŸ”— Multimodal Metrics<br/>â€¢ Cross-modal consistency<br/>â€¢ Joint representation quality<br/>â€¢ Information transfer"]
    end
    
    A1 --> B1
    A2 --> B2
    A3 --> B3
    
    style A1 fill:#e8f5e8
    style B1 fill:#fff3e0
```

---

## Data Specifications

### Data Dimensions and Formats

```mermaid
graph TB
    subgraph "Temporal Structure"
        T1["â±ï¸ Trial Duration: 2 seconds<br/>â€¢ -500ms to +1500ms<br/>â€¢ Stimulus-aligned<br/>â€¢ Standardized timing"]
        
        T2["ğŸ“Š Time Binning: 20ms<br/>â€¢ 100 bins per trial<br/>â€¢ 50 Hz effective sampling<br/>â€¢ Temporal resolution"]
        
        T3["ğŸ”„ Trial Organization<br/>â€¢ 70% training trials<br/>â€¢ 10% validation trials<br/>â€¢ 20% testing trials"]
    end
    
    subgraph "Neural Data Specs"
        N1["âš¡ Spike Data<br/>â€¢ Poisson count data<br/>â€¢ 100-800 neurons/session<br/>â€¢ Sparse matrix storage"]
        
        N2["ğŸŒŠ LFP Data (Optional)<br/>â€¢ 5 frequency bands<br/>â€¢ Power spectral density<br/>â€¢ 300ms sliding windows"]
        
        N3["ğŸ§  Brain Regions<br/>â€¢ Multi-area recordings<br/>â€¢ Region-specific analysis<br/>â€¢ Anatomical organization"]
    end
    
    subgraph "Behavioral Data Specs"
        B1["ğŸ¯ Static Variables<br/>â€¢ Choice: Binary (-1/1)<br/>â€¢ Block: Categorical (0.2/0.5/0.8)<br/>â€¢ Trial-level constants"]
        
        B2["ğŸ“ Dynamic Variables<br/>â€¢ Wheel speed: Continuous<br/>â€¢ Whisker motion: Continuous<br/>â€¢ Time-varying signals"]
        
        B3["ğŸ“Š Data Quality<br/>â€¢ Missing value handling<br/>â€¢ Outlier detection<br/>â€¢ Signal preprocessing"]
    end
    
    T1 --> N1
    T2 --> N2
    T3 --> N3
    
    N1 --> B1
    N2 --> B2
    N3 --> B3
    
    style T1 fill:#e3f2fd
    style N1 fill:#e8f5e8
    style B1 fill:#fff3e0
```

### Memory and Storage Optimization

```mermaid
graph LR
    subgraph "Data Storage Strategy"
        A1["ğŸ’¾ Raw Storage<br/>â€¢ HuggingFace datasets<br/>â€¢ Compressed format<br/>â€¢ Metadata preservation"]
        
        A2["âš¡ Training Storage<br/>â€¢ NumPy arrays<br/>â€¢ Memory-mapped files<br/>â€¢ Fast loading"]
        
        A3["ğŸ—œï¸ Compression<br/>â€¢ Sparse matrices<br/>â€¢ Efficient encoding<br/>â€¢ Reduced footprint"]
    end
    
    subgraph "Memory Management"
        B1["ğŸ“¥ Batch Loading<br/>â€¢ On-demand loading<br/>â€¢ Memory-efficient<br/>â€¢ Cache optimization"]
        
        B2["ğŸ”„ Data Streaming<br/>â€¢ Large dataset handling<br/>â€¢ Progressive loading<br/>â€¢ Resource management"]
        
        B3["âš™ï¸ Processing Pipeline<br/>â€¢ Parallel processing<br/>â€¢ Batch optimization<br/>â€¢ GPU memory efficiency"]
    end
    
    A1 --> B1
    A2 --> B2
    A3 --> B3
    
    style A1 fill:#e1f5fe
    style B1 fill:#f3e5f5
```

---

## Key Innovations

### Revolutionary Contributions

```mermaid
mindmap
  root((NEDS Innovations))
    Multi-Task Masking
      Mixed Strategy
      Dynamic Selection
      Cross-Modal Learning
      Simultaneous Tasks
    Session Stitching
      Variable Neurons
      Cross-Session Learning
      Scalable Architecture
      Unified Framework
    Multimodal Fusion
      Neural + Behavioral
      LFP Integration
      Temporal Alignment
      Joint Representation
    Transformer Design
      RoPE Encoding
      Flash Attention
      ScaleNorm Option
      Efficient Processing
    Training Framework
      Ray Tune Integration
      Multi-GPU Support
      Cross-Session Validation
      Hyperparameter Search
```

### Technical Breakthroughs

```mermaid
graph TD
    subgraph "Architectural Innovations"
        A1["ğŸ§© Session Stitching<br/>First framework to handle<br/>variable neuron counts<br/>across recording sessions"]
        
        A2["ğŸ­ Multi-Task Masking<br/>Single model performs<br/>encoding AND decoding<br/>simultaneously"]
        
        A3["ğŸ”„ Multimodal Fusion<br/>Unified processing of<br/>neural and behavioral<br/>data streams"]
    end
    
    subgraph "Performance Advances"
        B1["ğŸ“Š Cross-Session Generalization<br/>Models trained on some sessions<br/>generalize to unseen sessions<br/>without retraining"]
        
        B2["âš¡ Efficient Processing<br/>Sparse matrix optimization<br/>Flash attention integration<br/>Memory-efficient training"]
        
        B3["ğŸ¯ Joint Learning<br/>Simultaneous optimization<br/>of multiple objectives<br/>Improved performance"]
    end
    
    subgraph "Scientific Impact"
        C1["ğŸ§  Neuroscience Applications<br/>Brain-computer interfaces<br/>Neural prosthetics<br/>Cognitive modeling"]
        
        C2["ğŸ”¬ Research Tools<br/>Standardized benchmarks<br/>Open-source framework<br/>Reproducible results"]
        
        C3["ğŸš€ Future Directions<br/>Foundation models for neuroscience<br/>Multi-species adaptation<br/>Real-time applications"]
    end
    
    A1 --> B1 --> C1
    A2 --> B2 --> C2
    A3 --> B3 --> C3
    
    style A1 fill:#e3f2fd
    style B1 fill:#e8f5e8
    style C1 fill:#fff3e0
```

---

## Summary

NEDS represents a paradigm shift in computational neuroscience by:

1. **ğŸ”„ Unifying Encoding/Decoding**: Single model handles both neuralâ†’behavioral and behavioralâ†’neural tasks
2. **ğŸ§© Scalable Architecture**: Handles variable neuron counts across different recording sessions  
3. **ğŸ­ Intelligent Masking**: Dynamic masking strategy enables multi-task learning
4. **âš¡ Efficient Processing**: Optimized for large-scale neural data with sparse representations
5. **ğŸŒ Cross-Session Learning**: Generalizes across different experimental sessions and subjects

This comprehensive framework enables unprecedented analysis of neural-behavioral relationships at scale, opening new possibilities for brain-computer interfaces, neural prosthetics, and fundamental neuroscience research.

---

*For detailed implementation examples and usage instructions, see the main [README.md](README.md)*
